{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in classifying extracts of \"Allocine\" movie reviews. Sentiment Analysis litterature usually offers sentiment analysis on English corpuses while we will here be attempting to classify french reviews, which may be somehow different knowing that both languages have different grammar rules and sentence structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Context and theoretical background](#1.-Context-and-theoretical-background)\n",
    "\t* [1.1 Sentiment Analysis](#1.1-Sentiment-Analysis)\n",
    "    * [1.2 Language Modelling](#1.2-Language-Modelling)\n",
    "    * [1.3 Support Vector Machine](#1.3-Support-Vector-Machine)\n",
    "* [2. Application on Movie Reviews](#2.-Application-on-Movie-Reviews)\n",
    "    * [2.1 Python Setup](#2.1-Python-setup)\n",
    "    * [2.2 Input Format](#2.2-Input-Format)\n",
    "    * [2.3 Text Preprocessing](#2.3-Text-Preprocessing)\n",
    "    * [2.4 Putting it all together](#2.4-Putting-it-all-together)\n",
    "    * [2.5 Classification Model](#2.5-Classification-Model)\n",
    "    * [2.6 Model Evaluation](#2.6-Model-Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Context and theoretical background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Positive or negative movie review :</u>\n",
    "<UL TYPE=\"square\">\n",
    "<LI> Unbelievably disappointing <img src=\"../pictures/minus.png\" width=\"30\" height=\"30\">\n",
    "<LI> Full of zany characters and richly applied satire, and some great plot twists <img src=\"../pictures/plus.png\" width=\"30\" height=\"30\">\n",
    "<LI> this is the greatest screwball comedy ever filmed <img src=\"../pictures/plus.png\" width=\"30\" height=\"30\">\n",
    "<LI> It was pathetic. The worst part about it was the boxing scenes.<img src=\"../pictures/minus.png\" width=\"30\" height=\"30\">\n",
    "</UL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<u> Google Product Search :</u>\n",
    "<img src=\"../pictures/google_product.png\" width=\"700\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Twitter sentiment vs. Gallup Poll of Consumer Confidence </u>\n",
    "<UL TYPE=\"square\">\n",
    "<LI> Gallup :  global performance-management consulting company best known for its public opinion polls conducted worldwide\n",
    "<LI> Twitter sentiment based on \"Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series\" by Brendan O'Connor, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. 2010.\n",
    "</UL>\n",
    "<img src=\"../pictures/gallup_v2.png\" width=\"700\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Language Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Intuition:</u></b> The vocabulary is characteristic of the class ! In the example of movie reviews, if words like \"bad\" or \"boring\" are recurrent, it is highly probable that the review is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Problem:</u></b> This words are much less probable than common words like \"be\", \"if\", \"but\" ... etc and therefore can be \"hidden\" by those common words in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Solution:</u></b> Give weights to the words with TfIdf language modelling:\n",
    "<UL TYPE=\"squares\">\n",
    "    <LI> Term frequency (Luhn 1957) : frequency of the word <br/><br/>\n",
    "    <LI> Inverse document frequency (IDF) (Sparck Jones 1972)\n",
    "    <UL TYPE=\"circles\">\n",
    "        <LI> N is the total number of documents\n",
    "        <LI> $df_i$ is the documents with the word $i$\n",
    "        <LI> $idf_i = \\mathbb{\\log}(\\frac{N}{df_i})$\n",
    "    </UL> <br/><br/>\n",
    "    <LI> Tf-Idf: word i in document j: $$w_{ij} = tf_{ij} idf_i$$\n",
    "    $$w_{ij} = \\mathbb{C}(w_{ij})\\mathbb{\\log}(\\frac{N}{df_i})$$\n",
    "</UL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Text Classification:</u></b>\n",
    "<UL TYPE=\"squares\">\n",
    "    <LI> Input\n",
    "    <UL Type=\"circles\">\n",
    "        <LI> a document d\n",
    "        <LI> a fixed set of classes $ C = {c_1, c_2, ..., c_J} $\n",
    "    </UL>\n",
    "    <LI> Ouput : a predicted class $ c \\in C $\n",
    "</UL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Support vector machines (SVMs)</u></b> are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "A SVM constructs a hyper-plane or set of hyper-planes in a high or infinite dimensional space with the largest distance to the nearest training data points of any class (functional margin). In general, the larger the margin the lower the generalization error of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../pictures/svm.png\" height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Application on Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Python Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Pandas for array and data manipulation and Scikit-learn for text classification. Finally, using NLTK package, we can perform text processing and data cleaning (Lemmatization, stemming, remove stopwords and punctuation ... etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful modules\n",
    "import os, re, math, random\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier, Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Nltk\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.tokenize.stanford import StanfordTokenizer\n",
    "\n",
    "%run setup_workshop.py\n",
    "from setup_workshop import jar, model, tag_dict, lex_dict\n",
    "\n",
    "st_tok = StanfordTokenizer(jar, encoding='utf-8')\n",
    "st_tag = StanfordPOSTagger(model, jar, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Input Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Je n’aime pas utiliser cette phrase, je trouve...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speed and color in the eyes... Depuis Matrix, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Un an avant la consécration d'Avatar par la pr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Les frères Wachowski, à qui l’on doit l’impres...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S'il s'agissait seulement de partir du bon vie...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  Je n’aime pas utiliser cette phrase, je trouve...     1.0\n",
       "1  Speed and color in the eyes... Depuis Matrix, ...     1.0\n",
       "2  Un an avant la consécration d'Avatar par la pr...     1.0\n",
       "3  Les frères Wachowski, à qui l’on doit l’impres...     0.0\n",
       "4  S'il s'agissait seulement de partir du bon vie...     0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data set\n",
    "data_path = \"../dataset/data_allocine_workshop.csv\"\n",
    "data = pd.read_csv(data_path, delimiter = ';')\n",
    "\n",
    "# drop missing data\n",
    "data.dropna(inplace = True)\n",
    "\n",
    "# Head extract of the movie reviews dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Allocine move reviews which are already splitted into two classes : 0 for negative and 1 for positive. Negative reviews correspond to reviews rated 1.5 stars and lower. Positive reviews correspond to reviews rated 4.0 stars and higher.\n",
    "There are two columns : \"Review\" (text input) and \"Rating\" (text class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 : 15303\n",
      "1.0 : 18977\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for key, value in Counter(data.rating).items():\n",
    "    print(\"%s : %s\" % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excellent !!!\r",
      "\r\n",
      "Il faut vraiment voir le deux fois !\r",
      "\r\n",
      "C'est encore mieux ainsi. Le sang coule 2 fois!\r",
      "\r\n",
      "Tarantino nous ravi de ces scénarios !\n"
     ]
    }
   ],
   "source": [
    "review = data.iloc[random.randint(1, data.shape[0]),0]\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove numbers\n",
    "words = re.sub(r'\\d+', '', review)\n",
    "\n",
    "# remove elision\n",
    "words = words.replace(\"'\", \"e \")\n",
    "\n",
    "# remove punctuation and stopwords\n",
    "# lemmatize words\n",
    "words = st_tok.tokenize(words)\n",
    "tags = st_tag.tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Excellent', 'ADJ'), ('!!!', 'N'), ('Il', 'CLS'), ('faut', 'V'), ('vraiment', 'ADV'), ('voir', 'VINF'), ('le', 'DET'), ('deux', 'DET'), ('fois', 'NC'), ('!', 'PUNC'), ('Ce', 'DET'), ('est', 'V'), ('encore', 'ADV'), ('mieux', 'ADV'), ('ainsi', 'ADV'), ('.', 'PUNC'), ('Le', 'DET'), ('sang', 'NC'), ('coule', 'ADJ'), ('fois', 'N'), ('!', 'PUNC'), ('Tarantino', 'NPP'), ('nous', 'CLO'), ('ravi', 'VPP'), ('de', 'P'), ('ces', 'DET'), ('scénarios', 'NC'), ('!', 'PUNC')]\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def french_stem(tags_words, lexicon = lex_dict):\n",
    "    result = []\n",
    "    for tag in tags_words:\n",
    "        if tag[1] in tag_dict:\n",
    "            tag_fr = tag_dict[tag[1]]\n",
    "            if (tag_fr in tags_crit) and tag[0] in lex_dict[tag_fr]:\n",
    "                lemme_fr = lex_dict[tag_fr][tag[0]]\n",
    "                result.append(lemme_fr)\n",
    "                \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can synthesize all the above procedure in the following function that we can apply on all the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def review_to_words(review):\n",
    "    \n",
    "    try:\n",
    "            words = re.sub(r'\\d+', '', review)\n",
    "            words = words.replace(\"'\", \"e \")\n",
    "            \n",
    "            words = word_tokenize(words)\n",
    "            tags = st_tag.tag(words)\n",
    "        \n",
    "            clean_review = french_stem(tags)\n",
    "            \n",
    "            return(\" \".join(clean_review))\n",
    "    \n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'falloir vraiment voir fois être encore mieux ainsi sang fois ravir scénario'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_words(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going further, we usually split the dataset between a training set and a validation set.\n",
    "\n",
    "We usually fit the model on the training set and we use the validation set to decide wether the model is consistant enough or not. As a matter of fact, the validation set provides a vocabulary that the model might have never seen and a good accuracy score would show that the results of the model can be generalized beyond the training set alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training review : 0\n",
      "Training review : 100\n",
      "Training review : 200\n",
      "Training review : 300\n",
      "Training review : 400\n",
      "Training review : 500\n",
      "Training review : 600\n",
      "Training review : 700\n",
      "Training review : 800\n",
      "Training review : 900\n",
      "Training review : 1000\n",
      "Training review : 1100\n",
      "Training review : 1200\n",
      "Training review : 1300\n",
      "Training review : 1400\n",
      "Training review : 1500\n",
      "Training review : 1600\n",
      "Training review : 1700\n",
      "Training review : 1800\n",
      "Training review : 1900\n",
      "Training review : 2000\n",
      "Training review : 2100\n",
      "Training review : 2200\n",
      "Training review : 2300\n",
      "Training review : 2400\n",
      "Training review : 2500\n",
      "Training review : 2600\n",
      "Training review : 2700\n",
      "Training review : 2800\n",
      "Training review : 2900\n",
      "Training review : 3000\n",
      "Training review : 3100\n",
      "Training review : 3200\n",
      "Training review : 3300\n",
      "Training review : 3400\n",
      "Training review : 3500\n",
      "Training review : 3600\n",
      "Training review : 3700\n",
      "Training review : 3800\n",
      "Training review : 3900\n",
      "Training review : 4000\n",
      "Training review : 4100\n",
      "Training review : 4200\n",
      "Training review : 4300\n",
      "Training review : 4400\n",
      "Training review : 4500\n",
      "Training review : 4600\n",
      "Training review : 4700\n",
      "Training review : 4800\n",
      "Training review : 4900\n",
      "Training review : 5000\n",
      "Training review : 5100\n",
      "Training review : 5200\n",
      "Training review : 5300\n",
      "Training review : 5400\n",
      "Training review : 5500\n",
      "Training review : 5600\n",
      "Training review : 5700\n",
      "Training review : 5800\n",
      "Training review : 5900\n",
      "Training review : 6000\n",
      "Training review : 6100\n",
      "Training review : 6200\n",
      "Training review : 6300\n",
      "Training review : 6400\n",
      "Training review : 6500\n",
      "Training review : 6600\n",
      "Training review : 6700\n",
      "Training review : 6800\n",
      "Training review : 6900\n",
      "Training review : 7000\n",
      "Training review : 7100\n",
      "Training review : 7200\n",
      "Training review : 7300\n",
      "Training review : 7400\n",
      "Training review : 7500\n",
      "Training review : 7600\n",
      "Training review : 7700\n",
      "Training review : 7800\n",
      "Training review : 7900\n",
      "Training review : 8000\n",
      "Training review : 8100\n",
      "Training review : 8200\n",
      "Training review : 8300\n",
      "Training review : 8400\n",
      "Training review : 8500\n",
      "Training review : 8600\n",
      "Training review : 8700\n",
      "Training review : 8800\n",
      "Training review : 8900\n",
      "Training review : 9000\n",
      "Training review : 9100\n",
      "Training review : 9200\n",
      "Training review : 9300\n",
      "Training review : 9400\n",
      "Training review : 9500\n",
      "Training review : 9600\n",
      "Training review : 9700\n",
      "Training review : 9800\n",
      "Training review : 9900\n",
      "Training review : 10000\n",
      "Training review : 10100\n",
      "Training review : 10200\n",
      "Training review : 10300\n",
      "Training review : 10400\n",
      "Training review : 10500\n",
      "Training review : 10600\n",
      "Training review : 10700\n",
      "Training review : 10800\n",
      "Training review : 10900\n",
      "Training review : 11000\n",
      "Training review : 11100\n",
      "Training review : 11200\n",
      "Training review : 11300\n",
      "Training review : 11400\n",
      "Training review : 11500\n",
      "Training review : 11600\n",
      "Training review : 11700\n",
      "Training review : 11800\n",
      "Training review : 11900\n",
      "Training review : 12000\n",
      "Training review : 12100\n",
      "Training review : 12200\n",
      "Training review : 12300\n",
      "Training review : 12400\n",
      "Training review : 12500\n",
      "Training review : 12600\n",
      "Training review : 12700\n",
      "Training review : 12800\n",
      "Training review : 12900\n",
      "Training review : 13000\n",
      "Training review : 13100\n",
      "Training review : 13200\n",
      "Training review : 13300\n",
      "Training review : 13400\n",
      "Training review : 13500\n",
      "Training review : 13600\n",
      "Training review : 13700\n",
      "Training review : 13800\n",
      "Training review : 13900\n",
      "Training review : 14000\n",
      "Training review : 14100\n",
      "Training review : 14200\n",
      "Training review : 14300\n",
      "Training review : 14400\n",
      "Training review : 14500\n",
      "Training review : 14600\n",
      "Training review : 14700\n",
      "Training review : 14800\n",
      "Training review : 14900\n",
      "Training review : 15000\n",
      "Training review : 15100\n",
      "Training review : 15200\n",
      "Training review : 15300\n",
      "Training review : 15400\n",
      "Training review : 15500\n",
      "Training review : 15600\n",
      "Training review : 15700\n",
      "Training review : 15800\n",
      "Training review : 15900\n",
      "Training review : 16000\n",
      "Training review : 16100\n",
      "Training review : 16200\n",
      "Training review : 16300\n",
      "Training review : 16400\n",
      "Training review : 16500\n",
      "Training review : 16600\n",
      "Training review : 16700\n",
      "Training review : 16800\n",
      "Training review : 16900\n",
      "Training review : 17000\n",
      "Training review : 17100\n",
      "Training review : 17200\n",
      "Training review : 17300\n",
      "Training review : 17400\n",
      "Training review : 17500\n",
      "Training review : 17600\n",
      "Training review : 17700\n",
      "Training review : 17800\n",
      "Training review : 17900\n",
      "Training review : 18000\n",
      "Training review : 18100\n",
      "Training review : 18200\n",
      "Training review : 18300\n",
      "Training review : 18400\n",
      "Training review : 18500\n",
      "Training review : 18600\n",
      "Training review : 18700\n",
      "Training review : 18800\n",
      "Training review : 18900\n",
      "Training review : 19000\n",
      "Training review : 19100\n",
      "Training review : 19200\n",
      "Training review : 19300\n",
      "Training review : 19400\n",
      "Training review : 19500\n",
      "Training review : 19600\n",
      "Training review : 19700\n",
      "Training review : 19800\n",
      "Training review : 19900\n",
      "Training review : 20000\n",
      "Training review : 20100\n",
      "Training review : 20200\n",
      "Training review : 20300\n",
      "Training review : 20400\n",
      "Training review : 20500\n",
      "Training review : 20600\n",
      "Training review : 20700\n",
      "Training review : 20800\n",
      "Training review : 20900\n",
      "Training review : 21000\n",
      "Training review : 21100\n",
      "Training review : 21200\n",
      "Training review : 21300\n",
      "Training review : 21400\n",
      "Training review : 21500\n",
      "Training review : 21600\n",
      "Training review : 21700\n",
      "Training review : 21800\n",
      "Training review : 21900\n",
      "Training review : 22000\n",
      "Training review : 22100\n",
      "Training review : 22200\n",
      "Training review : 22300\n",
      "Training review : 22400\n",
      "Training review : 22500\n",
      "Training review : 22600\n",
      "Training review : 22700\n",
      "Training review : 22800\n",
      "Training review : 22900\n",
      "Test review : 0\n",
      "Test review : 100\n",
      "Test review : 200\n",
      "Test review : 300\n",
      "Test review : 400\n",
      "Test review : 500\n",
      "Test review : 600\n",
      "Test review : 700\n",
      "Test review : 800\n",
      "Test review : 900\n",
      "Test review : 1000\n",
      "Test review : 1100\n",
      "Test review : 1200\n",
      "Test review : 1300\n",
      "Test review : 1400\n",
      "Test review : 1500\n",
      "Test review : 1600\n",
      "Test review : 1700\n",
      "Test review : 1800\n",
      "Test review : 1900\n",
      "Test review : 2000\n",
      "Test review : 2100\n",
      "Test review : 2200\n",
      "Test review : 2300\n",
      "Test review : 2400\n",
      "Test review : 2500\n",
      "Test review : 2600\n",
      "Test review : 2700\n",
      "Test review : 2800\n",
      "Test review : 2900\n",
      "Test review : 3000\n",
      "Test review : 3100\n",
      "Test review : 3200\n",
      "Test review : 3300\n",
      "Test review : 3400\n",
      "Test review : 3500\n",
      "Test review : 3600\n",
      "Test review : 3700\n",
      "Test review : 3800\n",
      "Test review : 3900\n",
      "Test review : 4000\n",
      "Test review : 4100\n",
      "Test review : 4200\n",
      "Test review : 4300\n",
      "Test review : 4400\n",
      "Test review : 4500\n",
      "Test review : 4600\n",
      "Test review : 4700\n",
      "Test review : 4800\n",
      "Test review : 4900\n",
      "Test review : 5000\n",
      "Test review : 5100\n",
      "Test review : 5200\n",
      "Test review : 5300\n",
      "Test review : 5400\n",
      "Test review : 5500\n",
      "Test review : 5600\n",
      "Test review : 5700\n",
      "Test review : 5800\n",
      "Test review : 5900\n",
      "Test review : 6000\n",
      "Test review : 6100\n",
      "Test review : 6200\n",
      "Test review : 6300\n",
      "Test review : 6400\n",
      "Test review : 6500\n",
      "Test review : 6600\n",
      "Test review : 6700\n",
      "Test review : 6800\n",
      "Test review : 6900\n",
      "Test review : 7000\n",
      "Test review : 7100\n",
      "Test review : 7200\n",
      "Test review : 7300\n",
      "Test review : 7400\n",
      "Test review : 7500\n",
      "Test review : 7600\n",
      "Test review : 7700\n",
      "Test review : 7800\n",
      "Test review : 7900\n",
      "Test review : 8000\n",
      "Test review : 8100\n",
      "Test review : 8200\n",
      "Test review : 8300\n",
      "Test review : 8400\n",
      "Test review : 8500\n",
      "Test review : 8600\n",
      "Test review : 8700\n",
      "Test review : 8800\n",
      "Test review : 8900\n",
      "Test review : 9000\n",
      "Test review : 9100\n",
      "Test review : 9200\n",
      "Test review : 9300\n",
      "Test review : 9400\n",
      "Test review : 9500\n",
      "Test review : 9600\n",
      "Test review : 9700\n",
      "Test review : 9800\n",
      "Test review : 9900\n",
      "Test review : 10000\n",
      "Test review : 10100\n",
      "Test review : 10200\n",
      "Test review : 10300\n",
      "Test review : 10400\n",
      "Test review : 10500\n",
      "Test review : 10600\n",
      "Test review : 10700\n",
      "Test review : 10800\n",
      "Test review : 10900\n",
      "Test review : 11000\n",
      "Test review : 11100\n",
      "Test review : 11200\n",
      "Test review : 11300\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.33)\n",
    "train = train.reset_index(drop = True)\n",
    "test = test.reset_index(drop = True)\n",
    "\n",
    "train_reviews = []\n",
    "train_ratings = []\n",
    "\n",
    "for i, example in enumerate(train.review):\n",
    "    if (i%100 == 0):\n",
    "        print(\"Training review : %s\" %i)\n",
    "    clean_review = review_to_words(train.review[i])\n",
    "    if type(clean_review) == str:\n",
    "        train_reviews.append(clean_review)\n",
    "        train_ratings.append(train.rating[i])\n",
    "        \n",
    "test_reviews = []\n",
    "test_ratings = []\n",
    "\n",
    "for i, example in enumerate(test.review):\n",
    "    if (i%100 == 0):\n",
    "        print(\"Test review : %s\" %i)\n",
    "    clean_review = review_to_words(test.review[i])\n",
    "    if type(clean_review) == str:\n",
    "        test_reviews.append(clean_review)\n",
    "        test_ratings.append(test.rating[i])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned the data, we can proceed to the model.\n",
    "\n",
    "We start by building the term-document matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 5, max_df = .95)\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(train_reviews)\n",
    "train_data_features_tfidf = tfidf.fit_transform(train_data_features)\n",
    "\n",
    "train_data_features = train_data_features.toarray()\n",
    "train_data_features_tfidf = train_data_features_tfidf.toarray()\n",
    "\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist = np.sum(train_data_features, axis=0)\n",
    "dist_tfidf = np.sum(train_data_features_tfidf, axis=0)\n",
    "\n",
    "dict_features = dict(zip(vocab, dist))\n",
    "dict_features_tfidf = dict(zip(vocab, dist_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les 10 éléments les plus fréquents dans le corpus et leur tfidf : \n",
      "\n",
      "Mot: compte, tfidf \n",
      "\n",
      "être : 67429, 2559.0\n",
      "et : 44840, 1771.0\n",
      "avoir : 36873, 1710.0\n",
      "film : 35899, 1680.0\n",
      "ne : 25551, 1236.0\n",
      "pas : 22907, 1175.0\n",
      "plus : 12625, 766.0\n",
      "faire : 12216, 729.0\n",
      "voir : 11920, 870.0\n",
      "mais : 11524, 713.0\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "sorted_dict_features = sorted(dict_features.items(), key=operator.itemgetter(1), reverse = True)[:10]\n",
    "print(\"les 10 éléments les plus fréquents dans le corpus et leur tfidf : \\n\")\n",
    "print(\"Mot: compte, tfidf \\n\")\n",
    "for word, count in sorted_dict_features:\n",
    "    print(\"%s : %s, %s\" %(word, count, round(dict_features_tfidf[word],0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM with Gradient Descent optimization\n",
    "svm = SGDClassifier(loss = 'hinge')\n",
    "svm = svm.fit(train_data_features_tfidf, train_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_features = vectorizer.transform(test_reviews)\n",
    "test_data_features = tfidf.transform(test_data_features)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "y_pred = svm.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set : 91.57%\n"
     ]
    }
   ],
   "source": [
    "accuracy = roc_auc_score(test_ratings, y_pred)\n",
    "print(\"Accuracy on validation set : %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Ridge: 91.28%\n",
      "Accuracy Perceptron: 88.20%\n",
      "Accuracy Random Forest: 88.27%\n",
      "Accuracy Naive Bayes: 90.95%\n"
     ]
    }
   ],
   "source": [
    "def benchmark(clf, X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df = 5, max_df = .95)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', clf)\n",
    "        ])\n",
    "    pipeline.fit(X_train, Y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    return roc_auc_score(Y_test, y_pred)\n",
    "\n",
    "results = {}\n",
    "roc_curve_dict = {}\n",
    "\n",
    "classifiers = [(RidgeClassifier(tol = 1e-2, solver = 'sag'), 'Ridge'),\n",
    "              (Perceptron(n_iter = 50), 'Perceptron'),\n",
    "              (RandomForestClassifier(n_estimators = 100), 'Random Forest'),\n",
    "              (MultinomialNB(alpha = .01), 'Naive Bayes')]\n",
    "    \n",
    "for clf, name in classifiers:\n",
    "    score = benchmark(clf, train_reviews, train_ratings,\n",
    "                     test_reviews, test_ratings)\n",
    "    results[name] = score\n",
    "    print(\"Accuracy %s: %0.2f%%\" % (name, score * 100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
